[
    {
        "content": "<p>Hi all. If I have a state in a Markov category, what do I need to assume to be able to compute an expectation, and what does that look like diagrammatically?</p>",
        "id": 281359371,
        "sender_full_name": "Spencer Breiner",
        "timestamp": 1651784862
    },
    {
        "content": "<p>I think I would like to appeal to the law of large numbers and to say something like  the limiting average of i.i.d. copies of the state, which should limit to a Dirac distribution under some nice conditions. But maybe this characterization should be a theorem instead?<br>\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>l</mi><mi>i</mi><msub><mi>m</mi><mrow><mi>n</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></msub><mfrac><mn>1</mn><mi>n</mi></mfrac><mo stretchy=\"false\">(</mo><mi>n</mi><mo>⋅</mo><mi>p</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">E(p) = lim_{n\\to\\infty} \\frac{1}{n}(n\\cdot p)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">i</span><span class=\"mord\"><span class=\"mord mathnormal\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span></span></span></span></p>",
        "id": 281360171,
        "sender_full_name": "Spencer Breiner",
        "timestamp": 1651785259
    },
    {
        "content": "<p>I suppose that in many cases an expectation is an algebra for the probability monad, but I don't know what that looks like in general Markov categories.</p>",
        "id": 281360591,
        "sender_full_name": "Spencer Breiner",
        "timestamp": 1651785506
    },
    {
        "content": "<p>I imagine this should involve  \"representable\" Markov categories and distribution objects to dig deterministic values out of markov processes, but I didn't see any systematic discussion of expectation and variance in the <a href=\"https://arxiv.org/pdf/2010.07416.pdf\">that paper</a>.</p>",
        "id": 281360838,
        "sender_full_name": "Spencer Breiner",
        "timestamp": 1651785648
    },
    {
        "content": "<p>I can't help but I like the use of the term \"dig\" here.</p>",
        "id": 281373290,
        "sender_full_name": "John Baez",
        "timestamp": 1651794105
    }
]