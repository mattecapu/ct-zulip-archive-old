[
    {
        "content": "<p><time datetime=\"2022-05-26T17:00:00Z\">2022-05-26T17:00:00+00:00</time></p>\n<p><strong>Tai-Danae Bradley</strong>: <em>Entropy as an Operad Derivation</em></p>\n<p>This talk features a small connection between information theory, algebra, and topology‚Äînamely, a correspondence between Shannon entropy and derivations of the operad of topological simplices. We will begin with a brief review of operads and their representations with topological simplices and the real line as the main example. We then give a general definition for a derivation of an operad in any category with values in an abelian bimodule over the operad. The main result is that Shannon entropy defines a derivation of the operad of topological simplices, and that for every derivation of this operad there exists a point at which it is given by a constant multiple of Shannon entropy. We show this is compatible with, and relies heavily on, a well-known characterization of entropy given by Faddeev in 1956 and a recent variation given by Leinster.</p>\n<p>Zoom: <a href=\"https://topos-institute.zoom.us/j/84392523736?pwd=bjdVS09wZXVscjQ0QUhTdGhvZ3pUdz09\">https://topos-institute.zoom.us/j/84392523736?pwd=bjdVS09wZXVscjQ0QUhTdGhvZ3pUdz09</a><br>\nYouTube: <a href=\"https://youtu.be/_cAEfQQcELA\">https://youtu.be/_cAEfQQcELA</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"_cAEfQQcELA\" href=\"https://youtu.be/_cAEfQQcELA\"><img src=\"https://uploads.zulipusercontent.net/c605c8950dfac2eb7a828b70930465db65ed47fd/68747470733a2f2f692e7974696d672e636f6d2f76692f5f63414566515163454c412f64656661756c742e6a7067\"></a></div>",
        "id": 283277058,
        "sender_full_name": "Tim Hosgood",
        "timestamp": 1653288063
    },
    {
        "content": "<p>I have found a bit of time off from work to try to follow a little the many interesting courses on entropy and CT that have appeared recently.  <br>\n<a href=\"https://twitter.com/bblfish/status/1528969976950005760\">https://twitter.com/bblfish/status/1528969976950005760</a></p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/bblfish/status/1528969976950005760\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/77b199c7e82b7b9c52e9d03926bbf1970d09fe5d/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313030343332363736313630383431373238312f486a786a533942585f6e6f726d616c2e6a7067\"></a><p>\"Tutorial on Categorical Semantics of Entropy\" by <a href=\"https://twitter.com/johncarlosbaez\">@johncarlosbaez</a> and <a href=\"https://twitter.com/math3ma\">@math3ma</a>, starting with Shannon entropy. \nThis looks like it could be the course that was missing from Stiegler's philosophical work on negentropy \n<a href=\"https://twitter.com/ArsIndustrialis\">@ArsIndustrialis</a>\n<a href=\"https://t.co/DVjxPEDerg\">https://www.youtube.com/watch?v=5phJVSWdWg4</a></p><span>- The‚Äâüêü‚Äç‚Äç‚ÄâBabelFish (@bblfish)</span></div></div>",
        "id": 284100316,
        "sender_full_name": "Henry Story",
        "timestamp": 1653636833
    },
    {
        "content": "<p>My recent interest in Entropy came from listening to Bernard Stiegler a well known French philosopher (with quite an amazing history: he spend 5 years in prison after robbing a few banks in the 70s, sudied philosophy there, came out and did his Phd under Derrida on technics and time). He liked the long term views of humanity starting 2 million years ago with ability of pre-humans to control fire, which then changed them genetically over the ages leading to our ancestors. That story is captured by the greek myth of Prometheus stealing fire from the gods and giving it to humans, for which he was condemned to be chained to a rock and have an eagle eat his liver out every day which would then grow back (the liver in French is foi, which is homophonic in French to the word that we may translate as faith).<br>\n<a href=\"https://eduscol.education.fr/odysseum/le-mythe-de-promethee\">https://eduscol.education.fr/odysseum/le-mythe-de-promethee</a></p>",
        "id": 284100480,
        "sender_full_name": "Henry Story",
        "timestamp": 1653636964
    },
    {
        "content": "<p>Bernard Stiegler in the last 5 years or so developed the theme of entropy and emphasised the work of Shannon's negentropy as well as the relation of that to questions on what life is. Physical entropy has as endpoint the heat death of the universe and Life seems to be a local negentropic bubble that goes in the opposite direction to the physical system, creating more and more order where physical entropy is more about the creation of disorder (and hence why we have to keep organising ourselves, cleaning up, etc...). </p>\n<p>Is this notion of order vs disorder captured by the definitions of entropy that are being put forwards recently?</p>",
        "id": 284101555,
        "sender_full_name": "Henry Story",
        "timestamp": 1653637861
    },
    {
        "content": "<p>My guess is that <span class=\"user-mention\" data-user-id=\"275920\">@John Baez</span>'s definition on \"compositional thermostatics\" is taking this into account via the notion of Symmetric Monoidal Categories.</p>\n<blockquote>\n<p>Symmetric monoidal structures on a categories are another formalism that allows<br>\none to discuss morphisms with multiple inputs, and to permute these inputs [12], and in fact there is in fact a strong relationship between operads and symmetric monoidal categories. Every symmetric monoidal category has an underlying operad.</p>\n</blockquote>\n<p><a href=\"https://arxiv.org/pdf/2111.10315.pdf\">https://arxiv.org/pdf/2111.10315.pdf</a></p>\n<p><span class=\"user-mention\" data-user-id=\"276053\">@Brendan Fong</span> clearly relates Symmetric Monoidal Categories to biology in his thesis and to open and closed systems<br>\n<a href=\"https://twitter.com/bblfish/status/1398230682237911041\">https://twitter.com/bblfish/status/1398230682237911041</a></p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/bblfish/status/1398230682237911041\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/77b199c7e82b7b9c52e9d03926bbf1970d09fe5d/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313030343332363736313630383431373238312f486a786a533942585f6e6f726d616c2e6a7067\"></a><p><a href=\"https://twitter.com/johncarlosbaez\">@johncarlosbaez</a> <a href=\"https://twitter.com/ejpatters\">@ejpatters</a> Ah yes, the preface to Brendan Fong's thesis \"The Algebra of Open and Interconnected Systems\" <a href=\"https://t.co/bz9wmfPWvI\">https://arxiv.org/abs/1609.05382</a> should be of great interest to Philosophers as well as #linkeddata folks interested in what is behind the Open World Assumption. cc <a href=\"https://twitter.com/DJRoss70\">@DJRoss70</a> <a href=\"https://t.co/OiBEhy2Ddy\">https://twitter.com/bblfish/status/1398230682237911041/photo/1</a></p><span>- The‚Äâüêü‚Äç‚Äç‚ÄâBabelFish (@bblfish)</span><div class=\"twitter-image\"><a href=\"https://t.co/OiBEhy2Ddy\"><img src=\"https://uploads.zulipusercontent.net/bbb72c9e0cfed4b9b3f66b54bbac2457684d1846/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f453265444d43415830414532566c4c2e706e673a7468756d62\"></a></div></div></div>",
        "id": 284102510,
        "sender_full_name": "Henry Story",
        "timestamp": 1653638519
    },
    {
        "content": "<p>Stiegler's belief is these negentropic discoveries required rethinking all of philosophy and many other sciences as well, such as Economics. A key thinker in Economics he mentioned a lot was Georgescu Roegen, who studied under the famous \"Creative Destruction\" Schumpeter and who then wrote \"The entropy Law and the Economic Process\".   Stiegler thought that modern economists or poltics had not yet correctly integrated this thinking. Perhaps because the definitions of entropy were so muddled in the 1980s. So Perhaps these new analysis on entropy being put forward, linked to economics explained as Game theory (<span class=\"user-mention\" data-user-id=\"275901\">@Jules Hedges</span> ) can fix the misunderstandings  that stalled thinking on the subect? </p>\n<p><a href=\"https://en.wikipedia.org/wiki/Nicholas_Georgescu-Roegen\">https://en.wikipedia.org/wiki/Nicholas_Georgescu-Roegen</a></p>",
        "id": 284103566,
        "sender_full_name": "Henry Story",
        "timestamp": 1653639288
    },
    {
        "content": "<p>I get the feeling that the book <a href=\"https://arxiv.org/pdf/2012.02113.pdf\">Entropy and Diversity: the Axiomatic Approach</a> on the axiv may be the best starting point.</p>",
        "id": 284162135,
        "sender_full_name": "Henry Story",
        "timestamp": 1653672770
    },
    {
        "content": "<blockquote>\n<p>Is this notion of order vs disorder captured by the definitions of entropy that are being put forwards recently?</p>\n</blockquote>\n<p>I don't know any new definition of entropy being put forward recently, just new ways of understanding the usual ones.</p>",
        "id": 284196008,
        "sender_full_name": "John Baez",
        "timestamp": 1653694506
    },
    {
        "content": "<p>I don't think \"order vs disorder\" is a very helpful way to understand entropy.     At the very least you have to be extremely careful.  For example, the entropy of a frozen dead cat is much, <em>much</em> less than that of a warm live cat, and the latter is just a <em>very tiny</em> bit less than that of a warm dead cat.</p>",
        "id": 284196182,
        "sender_full_name": "John Baez",
        "timestamp": 1653694690
    },
    {
        "content": "<p>For my thoughts on entropy, <a href=\"https://math.ucr.edu/home/baez/entropy/\">check out my talk video and slides</a>.   Tom Leinster's book is really good, but of course much longer.   He's not a physicist, so for a physics perspective you should go somewhere else (and not my talk, I didn't have time for any physics).</p>",
        "id": 284196428,
        "sender_full_name": "John Baez",
        "timestamp": 1653694931
    }
]