---
layout: archive
title: Zulip Chat Archive
permalink: /stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html
---

<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/index.html">practice: our papers</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html">Categorical Foundations of Gradient-Based Learning</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com/">

{% raw %}

<a name="228809432"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/258900-practice%3A%20our%20papers/topic/Categorical%20Foundations%20of%20Gradient-Based%20Learning/near/228809432" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Bruno Gavranovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html#228809432">(Mar 04 2021 at 16:57)</a>:</h4>
<p>Hi all, we just put up our paper <a href="https://arxiv.org/abs/2103.01931">Categorical Foundations of Gradient-Based Learning</a> up on arxiv. This is joint work with <span class="user-mention" data-user-id="317561">@Geoff Cruttwell</span> , Neil Ghani, <span class="user-mention" data-user-id="316240">@Paul</span> and <span class="user-mention" data-user-id="351836">@Fabio Zanasi</span> .</p>
<p>We provided a 2-categorical foundation for many types of neural networks in terms three things: 1)  parameterized maps (the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">P</mi><mi mathvariant="bold">a</mi><mi mathvariant="bold">r</mi><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{Para}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">P</span><span class="mord mathbf">a</span><span class="mord mathbf">r</span><span class="mord mathbf">a</span></span></span></span></span> construction), 2) lenses, and 3) reverse derivative categories.<br>
This includes learning on well-known Euclidean spaces, but also weird things like learning on Boolean Circuits (since, surprisingly, they are a reverse derivative category too).<br>
It also turns out a bunch of things called "optimizers" are lenses as well - starting from standard gradient descent, through Momentum and Nesterov Momentum to more complex optimizers like Adagrad and Adam. </p>
<p>This was also a bit surprising but it somehow all fits together - since optimizers are lenses they end up being 2-cells in our category. But I'll stop here and defer you to all the details in the paper.</p>



<a name="228809872"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/258900-practice%3A%20our%20papers/topic/Categorical%20Foundations%20of%20Gradient-Based%20Learning/near/228809872" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Bruno Gavranovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html#228809872">(Mar 04 2021 at 17:00)</a>:</h4>
<p>Looking for any feedback or thoughts you may have about it :)</p>



<a name="228819101"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/258900-practice%3A%20our%20papers/topic/Categorical%20Foundations%20of%20Gradient-Based%20Learning/near/228819101" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Giorgos Bakirtzis <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html#228819101">(Mar 04 2021 at 17:52)</a>:</h4>
<p>This is great <span class="user-mention" data-user-id="276875">@Bruno Gavranovic</span> I will be reading this in the next couple of weeks. Will let you know if I have any comments</p>



<a name="228819595"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/258900-practice%3A%20our%20papers/topic/Categorical%20Foundations%20of%20Gradient-Based%20Learning/near/228819595" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jules Hedges <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html#228819595">(Mar 04 2021 at 17:56)</a>:</h4>
<p>Well I just discovered that this stream, which I previously wasn't subscribed to, has a <em>lot</em> of stuff I'm interested in</p>



<a name="228821530"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/258900-practice%3A%20our%20papers/topic/Categorical%20Foundations%20of%20Gradient-Based%20Learning/near/228821530" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Bruno Gavranovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html#228821530">(Mar 04 2021 at 18:07)</a>:</h4>
<p>I'll also supplement the paper with a <a href="https://youtu.be/tKM8JdXJEII">video of the presentation I did on the paper</a>. The video should be much more informal, visual and it also takes a slightly different perspective on the paper.</p>
<div class="youtube-video message_inline_image"><a data-id="tKM8JdXJEII" href="https://youtu.be/tKM8JdXJEII"><img src="https://i.ytimg.com/vi/tKM8JdXJEII/default.jpg"></a></div>



<a name="228825358"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/258900-practice%3A%20our%20papers/topic/Categorical%20Foundations%20of%20Gradient-Based%20Learning/near/228825358" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Spencer Breiner <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html#228825358">(Mar 04 2021 at 18:29)</a>:</h4>
<p>Loving it! You mention that reverse differential categories are good for classification b/c the target dimension is low. Does that mean we should expect  forward differentials to be better for generative tasks?</p>



<a name="228830298"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/258900-practice%3A%20our%20papers/topic/Categorical%20Foundations%20of%20Gradient-Based%20Learning/near/228830298" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Bruno Gavranovic <a href="https://mattecapu.github.io/ct-zulip-archive/stream/258900-practice:-our-papers/topic/topic_Categorical.20Foundations.20of.20Gradient-Based.20Learning.html#228830298">(Mar 04 2021 at 19:00)</a>:</h4>
<p>That's a great question and something I've been wondering about as well. I suspect so, but honestly, I don't know - I'd love to hear more from some AI expert on this</p>



{% endraw %}

<hr><p>Last updated: May 08 2023 at 00:28 UTC</p>