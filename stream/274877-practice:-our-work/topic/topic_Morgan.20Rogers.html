---
layout: archive
title: Zulip Chat Archive
permalink: /stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html
---

<h2>Stream: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/index.html">practice: our work</a></h2>
<h3>Topic: <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html">Morgan Rogers</a></h3>

<hr>

<base href="https://categorytheory.zulipchat.com/">

{% raw %}

<a name="237162200"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/237162200" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#237162200">(May 03 2021 at 13:42)</a>:</h4>
<p>Having just uploaded my paper on topological monoid actions to the arXiv (which I will post about on <a class="stream" data-stream-id="258900" href="/#narrow/stream/258900-practice.3A-our-papers">#practice: our papers</a> once it's online tomorrow), now seems like a good time to take stock on what I'm up to.</p>
<ul>
<li>First, my ongoing collaborations, which are at varying levels of activity:<ul>
<li>With <span class="user-mention silent" data-user-id="282722">Jens Hemelaer</span>, work on toposes of discrete monoid actions and geometric morphisms between them. Our current project is an exploration of what factorization systems for geometric morphisms look like in this special case. We have most of a paper on the "Root" of a monoid tucked away too, which we should eventually get around to finishing.</li>
<li>With <span class="user-mention silent" data-user-id="284376">Riccardo Zanfa</span>, work on (Street) fibrations, especially between categories with pullbacks and toposes. That work may depend on...</li>
<li>With <span class="user-mention silent" data-user-id="276092">Nathanael Arkor</span>, a small project on free cocompletions of (internal) categories with respect to manageable classes of colimit.</li>
<li>With <span class="user-mention silent" data-user-id="276037">Jade Master</span>, a (currently dormant) investigation of whether or not the category of symmetric monoidal categories is monadic over the category of Petri nets, and more generally whether the category of Q-categories is monadic over the category of Q-nets for a Lawvere theory Q.</li>
</ul>
</li>
<li>The third entry above will help me understand the right construction of syntactic categories for <strong>supercompactly generated theories</strong>, which is what I'm calling theories classified by supercompactly generated toposes. While it's of course possible to express these as geometric theories, the canonical sites for supercompactly generated toposes are <em>reductive sites</em>, which are characterized by the existence of particular colimits, and I would like to develop a standalone syntax for such categories.</li>
<li>Whatever the outcome of the preceding point, I want to extract a characterization of theories classified by toposes of topological monoid actions. This will be the key step in making <strong>Topological Semi-Galois Theory</strong>, the analogue of Galois Theory with monoids in place of groups, a viable tool.</li>
<li>The final thing I'm hoping to get done before my PhD ends (in October <span aria-label="dizzy" class="emoji emoji-1f635" role="img" title="dizzy">:dizzy:</span> ) is to establish what the semi-Galois analogue of the classical Galois theory of field extensions should be. I already have some idea of what this will look like, but I need to do a lot more work to clarify the picture.</li>
</ul>
<p>Beyond the end of my PhD... It's clear that some of the work above is going to have to take place after my PhD ends. If you happen to be or know someone who can offer me a post-doc position where any of the above would be relevant, then please get in touch <span aria-label="stuck out tongue wink" class="emoji emoji-1f61c" role="img" title="stuck out tongue wink">:stuck_out_tongue_wink:</span> .</p>



<a name="252418969"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/252418969" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#252418969">(Sep 08 2021 at 07:39)</a>:</h4>
<p>This stream has a lot of big names posting in it, so I figure it would be nice thesis-writing procrastination to update my own thread, since I'm just a student. Here's what I've got on in the near future:</p>
<ul>
<li><strong>Finish writing my thesis.</strong></li>
<li>Find a CT postdoc or alternatively some funding to pursue research into AI ethics/philosophy, both preferably in Europe.</li>
</ul>
<p>It's a bit shorter than other folks' entries; I hope that's relatable.</p>



<a name="252494970"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/252494970" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jade Master <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#252494970">(Sep 08 2021 at 16:53)</a>:</h4>
<p>Looks very similar to my to do for most of last year :)</p>



<a name="255759138"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/255759138" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#255759138">(Oct 01 2021 at 15:10)</a>:</h4>
<p>Update: thesis done! I had a breakthrough in the last month that I couldn't resist squeezing in. It's a relief to have submitted it.</p>



<a name="265534007"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265534007" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265534007">(Dec 20 2021 at 08:35)</a>:</h4>
<p>I defended my thesis last Tuesday. Should be up on the arXiv today.<br>
I'm a doctor now yay!</p>



<a name="265576756"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265576756" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Valeria de Paiva <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265576756">(Dec 20 2021 at 15:22)</a>:</h4>
<p>Congratulations! <span aria-label="tada" class="emoji emoji-1f389" role="img" title="tada">:tada:</span></p>



<a name="265649048"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265649048" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> David Michael Roberts <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265649048">(Dec 21 2021 at 05:29)</a>:</h4>
<p>Congratulations!</p>



<a name="265649072"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265649072" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> David Michael Roberts <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265649072">(Dec 21 2021 at 05:29)</a>:</h4>
<p>One small note <span class="user-mention" data-user-id="277473">@Morgan Rogers (he/him)</span>  : when I tried to get the pdf of your thesis from the arXiv, it failed! I got the postscript ok, though.</p>



<a name="265661135"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265661135" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265661135">(Dec 21 2021 at 08:54)</a>:</h4>
<p>Hmm thanks for letting me know <span class="user-mention" data-user-id="276422">@David Michael Roberts</span>, I'll check it later.</p>



<a name="265661227"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265661227" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ivan Di Liberti <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265661227">(Dec 21 2021 at 08:55)</a>:</h4>
<p>I have the same issue, but also the ps fails for me.</p>



<a name="265703218"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265703218" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ulrik Buchholtz <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265703218">(Dec 21 2021 at 16:13)</a>:</h4>
<p>The pdf from the arXiv worked for me now. Congratulations! (BTW, you could certainly also cross-list to math.LO.)</p>



<a name="265707766"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/265707766" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jonathan Weinberger <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#265707766">(Dec 21 2021 at 16:50)</a>:</h4>
<p>Congratulations <span class="user-mention" data-user-id="277473">@Morgan Rogers (he/him)</span> ! The PDF is now working for me as well, after it initially hadn't this morning</p>



<a name="276441625"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/276441625" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#276441625">(Mar 24 2022 at 07:58)</a>:</h4>
<p>Those of you that have spoken to me in the past 6 months or more probably know that I am doing a research project on AI Safety. I figure I might as well share what I've done so far here, in case there is some interest. The aim of the project is to provide some formal grounding for the intuitive concept of <strong>goal-directedness</strong>, a notion which appears in many stories about how sufficiently capable AI could go bad.</p>
<p>In my <a href="https://www.lesswrong.com/posts/7X9KKqgZa7edknKPm/goal-directedness-my-baseline-beliefs">preliminary post</a> I discuss the ideas I had about this before the project began.<br>
In my <a href="https://www.lesswrong.com/posts/KJPRC3cgtxSXpZEQZ/goal-directedness-exploring-explanations">first real post</a> I talked about criteria for judging explanations, since this is a tool I want to apply to assessing goal-directedness.<br>
In my <a href="https://www.lesswrong.com/posts/oZCeun2v3Xd3ncrHt/goal-directedness-imperfect-reasoning-limited-knowledge-and">second post</a> I break down the structure of explanations with the intent of giving more flexibility to what counts as goal-directed behaviour.</p>
<p>Category theory gets a mention in the last post, although only incidentally (because I happen to include the category of world models that one could use as a parameter).</p>



<a name="288271638"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288271638" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288271638">(Jul 02 2022 at 13:58)</a>:</h4>
<p>The <a href="https://www.lesswrong.com/posts/jgYGZD2zRK6nncJd5/goal-directedness-tackling-complexity">third post in my AI project</a> is finally up.</p>
<p>It's all about <strong>complexity</strong>. The aim of the post was to build an inclusive, flexible, semi-formal notion of complexity, which includes the ideas that you would find in any branch of complexity theory.</p>
<p>I did try to make it accessible to a wide audience, but I couldn't resist putting some pretty abstract maths in there. I'm curious to know what people reading from here get out of it. Enjoy <span aria-label="grinning face with smiling eyes" class="emoji emoji-1f601" role="img" title="grinning face with smiling eyes">:grinning_face_with_smiling_eyes:</span></p>



<a name="288277669"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288277669" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Fabrizio Genovese <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288277669">(Jul 02 2022 at 16:09)</a>:</h4>
<blockquote>
<p>Even though "computation" is in the name, the mathematically interesting details of computational complexity are considered to be those which are independent of specific implementation. For this reason, it is typical to consider an implementation-independent version</p>
</blockquote>
<p>Indeed, I always found very peculiar that the notion of computational complexity one traditionally uses to study algorithms is given in the context of Turing machines. We have widly different models of computations (Turing, partial functions, lambda calculus) that have been proved to be able to compute the same stuff. Yet, in defining complexity theory we settled on one choice, in a way that's not invariant</p>



<a name="288309524"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288309524" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288309524">(Jul 03 2022 at 05:37)</a>:</h4>
<p>I believe a computation takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> steps to do in one of these models iff it does in any other, with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> independent of the model.</p>



<a name="288309577"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288309577" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288309577">(Jul 03 2022 at 05:39)</a>:</h4>
<p>I could be wrong, but that's the sort of invariance I'd expect, and that's enough to justify why people say it takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> time to do some sort of computation, or things like that.</p>



<a name="288314932"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288314932" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288314932">(Jul 03 2022 at 08:09)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275920">John Baez</span> <a href="#narrow/stream/274877-practice.3A-our-work/topic/Morgan.20Rogers/near/288309524">said</a>:</p>
<blockquote>
<p>I believe a computation takes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> steps to do in one of these models iff it does in any other, with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> independent of the model.</p>
</blockquote>
<p>The translation is sometimes quadratic rather than linear, so if it's <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> in one then it will be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mrow><mn>2</mn><mi>k</mi></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^{2k})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> in the others. To get a model-invariant complexity class we therefore have to pass from specific index to "polynomial time". I also give other problems which the coarser complexity classes avoid.</p>
<p>There is some intuition for this: if I have a specific computational task in mind, I might be able to design a machine that is particularly efficient at it while still being able to perform other computations. My advisor gave me an example of a machine that can perform computations on graphs efficiently; more generally, the speed at which a computer can perform certain computations on some data structure depends on how that structure is loaded into the machine, and encoding a graph on the tape of a Turing machine is hard to do efficiently. The claim is that the improvement in efficiency will only be polynomial.</p>
<p>Of course, for this to be true one also needs to control which operations count as basic. Beta-reductions in lambda calculus are <a href="https://www.win.tue.nl/~hzantema/israccattoli.pdf">a bit too powerful</a>, for instance.</p>



<a name="288593363"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288593363" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> John Baez <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288593363">(Jul 05 2022 at 21:18)</a>:</h4>
<p>Thanks.  This is interesting because many algorithms on Wikipedia come with explicit statements that they have complexity of the form <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> with a specific exponent <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>.   For example:</p>
<p><a href="https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm">https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm</a></p>
<p>So, it looks like they have an accepted way of modeling the computations, to say more than just "polynomial time".</p>
<p>(In my example <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> is the number of vertices of a graph; we sometimes have a more complicated version of complexity that depends on several parameters like the number of edges and the number of vertices, but my point is about something else.)</p>



<a name="288602610"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288602610" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alex Gryzlov <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288602610">(Jul 05 2022 at 23:09)</a>:</h4>
<p>There has been a lot of work recently on mechanizing synthetic computability theory, mostly centered around the <a href="https://github.com/uds-psl/coq-library-undecidability">https://github.com/uds-psl/coq-library-undecidability</a> repo, so maybe we'll eventually get a nicer form of complexity theory too.</p>



<a name="288602869"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288602869" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alex Gryzlov <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288602869">(Jul 05 2022 at 23:13)</a>:</h4>
<p>They already seem to have some complexity stuff built on top of it, e.g. <a href="https://drops.dagstuhl.de/opus/volltexte/2021/13915/">https://drops.dagstuhl.de/opus/volltexte/2021/13915/</a></p>



<a name="288629662"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288629662" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288629662">(Jul 06 2022 at 06:44)</a>:</h4>
<p><span class="user-mention silent" data-user-id="275920">John Baez</span> <a href="#narrow/stream/274877-practice.3A-our-work/topic/Morgan.20Rogers/near/288593363">said</a>:</p>
<blockquote>
<p>So, it looks like they have an accepted way of modeling the computations, to say more than just "polynomial time".</p>
</blockquote>
<p>I would say that these complexity statements are based on a "model-free" set-up rather than a "model-invariant" one: the complexity of an algorithm is measured in terms of the number of basic operations involved, without actually making reference to any particular implementation (where said operations might not be basic at all!) and the complexity of the problem is the complexity of the least complex algorithm. I hope that idea also comes across in what I wrote..!</p>



<a name="288629893"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288629893" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288629893">(Jul 06 2022 at 06:48)</a>:</h4>
<p><span class="user-mention silent" data-user-id="276047">Alex Gryzlov</span> <a href="#narrow/stream/274877-practice.3A-our-work/topic/Morgan.20Rogers/near/288602610">said</a>:</p>
<blockquote>
<p>There has been a lot of work recently on mechanizing synthetic computability theory, mostly centered around the <a href="https://github.com/uds-psl/coq-library-undecidability">https://github.com/uds-psl/coq-library-undecidability</a> repo, so maybe we'll eventually get a nicer form of complexity theory too.</p>
</blockquote>
<p>What do you mean by "a nicer form of complexity theory"? I did see a talk recently (at the last Chocola meeting in Lyon) about synthetic computability theory, where the focus was around axiomatizing Church-Turing in order to be able to formalize proofs involving it; it was possibly the most convincing use-case for formalization that I've seen.</p>



<a name="288634984"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288634984" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Damiano Mazza <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288634984">(Jul 06 2022 at 07:56)</a>:</h4>
<p><span class="user-mention silent" data-user-id="277473">Morgan Rogers (he/him)</span> <a href="#narrow/stream/274877-practice.3A-our-work/topic/Morgan.20Rogers/near/288629662">said</a>:</p>
<blockquote>
<p><span class="user-mention silent" data-user-id="275920">John Baez</span> <a href="#narrow/stream/274877-practice.3A-our-work/topic/Morgan.20Rogers/near/288593363">said</a>:</p>
<blockquote>
<p>So, it looks like they have an accepted way of modeling the computations, to say more than just "polynomial time".</p>
</blockquote>
<p>I would say that these complexity statements are based on a "model-free" set-up rather than a "model-invariant" one: the complexity of an algorithm is measured in terms of the number of basic operations involved</p>
</blockquote>
<p>It is "model-free" in that we are abstracting from the cost of basic operations (which are all counted as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span>), but it does depend on an important, model-specific assumption: that memory is <em>random-access</em>.  In other words, in the practice of algorithms, people have taken as default the RAM (<a href="https://www.wikiwand.com/en/Random-access_machine">Random Access Machine</a>) model of computation.  When people say, without any further comment, that "this algorithm has complexity <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(f(n))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">))</span></span></span></span>", they are thinking of an implementation on a RAM-like model.  This is justified by the fact that, from the very early days, actual computers are RAM-like (much more than they are Turing-machine-like).</p>
<p>For example, the Floyd-Warshall algorithm does not have complexity <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> on a (multitape) Turing machine, but that's <em>not</em> because the basic semiring operations in question cannot be implemented in constant time on a Turing machine (in some important cases, they can: for instance, for the Boolean semiring <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo><mo separator="true">,</mo><mo>∨</mo><mo separator="true">,</mo><mo>∧</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\{0,1\},\lor,\land)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">({</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">}</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∨</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∧</span><span class="mclose">)</span></span></span></span>, which is all we need if we want to compute transitive closure rather than shortest paths).  Rather, it is because Turing machines are not random-access, and reading an entry in the adjacency matrix of the input graph spread out on the input tape is not a constant-time operation.  And even if you considered random-access Turing machines, you would <em>still</em> have logarithmic factors showing up because manipulating the pointers to the input tape does not have constant cost (the pointers are themselves tapes).</p>
<p>So, in reality, a better interpretation of the unadorned sentence "this algorithm runs in time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(f(n))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">))</span></span></span></span>" is "this algorithm runs in time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(f(n))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">))</span></span></span></span> on a RAM".  Or, in more practical terms, "when all basic data (typically, integers) fit in less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> bits (where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> is some technology-related constant; e.g., these days, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">k=64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">64</span></span></span></span>), this algorithm runs in time <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(f(n))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">))</span></span></span></span> on an actual computer".</p>
<p>Moral of the story: the complexity analysis of algorithms is much less abstract and model-free than what we would like it to be!  But that does not affect the meaningfulness of "robust" complexity classes (like logspace, polytime, deterministic or not, etc.), which are model-invariant.</p>



<a name="288635468"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288635468" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Tom Hirschowitz <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288635468">(Jul 06 2022 at 08:00)</a>:</h4>
<p>Not an expert either, but my feeling is that there are two distinct communities talking about complexity:</p>
<ul>
<li>
<p>in complexity theory, people are interested in complexity classes (polynomial, linear, etc),</p>
</li>
<li>
<p>in algorithms, they are interested in precise bounds (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(n^k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, etc).</p>
</li>
</ul>
<p>(I'd be very interested in any categorical, model-independent, invariant, ... approach to both! Ping <span class="user-mention" data-user-id="276839">@Damiano Mazza</span>...)</p>



<a name="288639416"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288639416" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Damiano Mazza <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288639416">(Jul 06 2022 at 08:36)</a>:</h4>
<p>Yes, that's absolutely true.  And in the first community, the model of choice is Turing machines, whereas in the second community, it is RAMs.</p>
<p>However, as I said, most complexity classes of interest in complexity theory are model-invariant, or, even better, have equivalent definitions which do not mention any model at all (see for example <a href="https://www.wikiwand.com/en/Descriptive_complexity_theory">descriptive complexity theory</a>).  Turing machines are just a convenient choice motivated by the fact that their time and space cost models are self-evident and essentially unquestionable, but they are not inevitable for formulating complexity theory.  Here, categorical approaches are definitely possible and, hopefully, relevant (I hope to be able to say something more precise soon!).</p>
<p>In the case of algorithms, there is no hope: precise running times (e.g., up to the exponent in a polynomial bound) depend on the model.  We are especially interested in how algorithms behave on the computational devices we use every day, and so we tend to pick models that are close to them.  In any case, it is possible to develop categorical approaches to both the languages describing algorithms and the relationship that these have with the cost models of interest.  The first aspect is, basically, modern programming languages theory <span aria-label="upside down" class="emoji emoji-1f643" role="img" title="upside down">:upside_down:</span> (and you know more than me about it!).  The second aspect is less developed, and certainly more of a present-day challenge, but there is already interesting work on the topic.  A couple of examples that come to my mind now are Blelloch and Harper's approach to time and space cost models in functional programming languages (although it does not explicitly use any category theory) and Danner and Licata's papers on denotational cost semantics (which uses monads!).  But there's certainly more out there.</p>



<a name="288659248"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288659248" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Fabrizio Genovese <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288659248">(Jul 06 2022 at 12:02)</a>:</h4>
<p>Thanks <span class="user-mention" data-user-id="276839">@Damiano Mazza</span> ,  this clarifies a lot. So there is some sanity in the basic definitions of complexity theory, I'm very happy to hear that lol</p>



<a name="288670782"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288670782" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Nguyễn Lê Thành Dũng <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288670782">(Jul 06 2022 at 13:35)</a>:</h4>
<p>There is also "fine-grained complexity theory" which tries to prove lower bounds on the k in O(n^k), with many interesting results (conditional on conjectures such as the exponential time hypothesis for SAT). Also, there's an old theorem that says that for any k, l &gt;= 2, k-tape and l-tape Turing machines can simulate each other with a logarithmic overhead in time. So I'd say that even from a complexity-theoretic POV, "time O(n^k * polylog(n))" is a reasonably mathematically robust notion.</p>



<a name="288670991"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288670991" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Nguyễn Lê Thành Dũng <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288670991">(Jul 06 2022 at 13:37)</a>:</h4>
<p>(That said, I've never really understood what is being really achieved when one shows that a log factor can be brought down to inverse-ackermann in some algorithm…)</p>



<a name="288671457"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288671457" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Nguyễn Lê Thành Dũng <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288671457">(Jul 06 2022 at 13:41)</a>:</h4>
<p>Relatedly, I'd be interested in what other computer scientists think of this series of blog posts geared towards programmers: <a href="https://www.ilikebigbits.com/2014_04_21_myth_of_ram_1.html">https://www.ilikebigbits.com/2014_04_21_myth_of_ram_1.html</a> (personally, I'm not really convinced)</p>



<a name="288676169"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/288676169" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#288676169">(Jul 06 2022 at 14:10)</a>:</h4>
<p>The black hole analysis is bogus and the empirical results don't correspond to the theory he presents (where the speed limit of information transfer is what creates the bound), but a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mroot><mi>N</mi><mn>3</mn></mroot><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\sqrt[3]{N})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1767em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord sqrt"><span class="root"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8102em;"><span style="top:-2.988em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size6 size1 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9267em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.8867em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1133em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span> bound in general and a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msqrt><mi>N</mi></msqrt><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\sqrt{N})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1767em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9267em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-2.8867em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1133em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span> bound for a planar architecture seems reasonable.</p>
<p>Ultimately there are yet further operations one could penalize in the complexity calculation by examining finer and finer grains of logistical detail in the operation of a particular model of computation. This is the kind of assumption it is helpful to be conscious of when doing complexity theory, I think: any amount of abstraction amounts to taking some operations for granted, treating them as cost-free. Acknowledging this maintains the focus on what a given notion of complexity is "actually" measuring.</p>



<a name="294044877"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/294044877" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#294044877">(Aug 18 2022 at 10:01)</a>:</h4>
<p>It turned out that my post on complexity wasn't quite sufficient for the complexity measures I needed to build for goal-directedness, so I wrote an extension of it in a <a href="https://www.lesswrong.com/posts/e936w9JzDP4WqQjcc/goal-directedness-relativising-complexity">fourth post</a>. This one is about <strong>relative complexity</strong>. It's not especially comprehensive; it's more of a record of me working out what relativisation can mean and do.</p>



<a name="294122561"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/294122561" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> David Egolf <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#294122561">(Aug 18 2022 at 16:31)</a>:</h4>
<p>Thanks for sharing these posts! I would like to try and find time and energy to read them properly, as mathematical notions of complexity are something new and exciting to me. However, in an medical imaging context, I have worked a little bit with something called "sparsity", which is something I've thought of as measuring the simplicity of something.</p>
<p>In a vector space <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>, if we choose a basis <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> so that we can write a vector <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> as a sum of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> non-zero basis vectors, we say that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>-sparse with respect to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>. (Hopefully I am remembering this right). How sparse a vector is depends on the basis that we choose, which reminds me of your section entitled "fragility of complexity measures".</p>
<p>We can use sparsity to help solve optimization problems, where the intuition is that the real solution is "simple", which we approximate by saying it should be pretty sparse with respect to a chosen basis. A challenge here is choosing a basis that makes the unknown solution actually sparse. It's my guess that people are using machine learning these days to find sparsifying basis vectors. Anyways, this approach can help reject "artifacts" in images, and reduce the impact of noise - intuitively because these additions to an image make them less simple.</p>
<p>Do you happen to know if the sparsity of a vector with respect to a basis is somehow related to the kind of complexity you are talking about?</p>
<p>Edit: Upon reading a little more carefully, I see you talk about the squared length of vectors in a given basis as an example of how we can vary complexity by changing the building blocks involved. The example of sparsity is a little different, but very similar, so I think I understand that sparsity probably does fit under the umbrella of the things you're talking about here. Cool!</p>



<a name="294410669"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/294410669" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Morgan Rogers (he/him) <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#294410669">(Aug 20 2022 at 08:53)</a>:</h4>
<p>Yes indeed! It's really interesting to hear someone studying the dual problem of choosing a complexity measure out of a particular family which makes the chosen instance simple. For a single vector, the problem is less interesting, but for simultaneously making a whole family of vectors as sparse as possible I imagine it gets difficult fast. <span aria-label="grinning face with smiling eyes" class="emoji emoji-1f601" role="img" title="grinning face with smiling eyes">:grinning_face_with_smiling_eyes:</span></p>



<a name="294446625"></a>
<h4><a href="https://categorytheory.zulipchat.com/#narrow/stream/274877-practice%3A%20our%20work/topic/Morgan%20Rogers/near/294446625" class="zl"><img src="https://mattecapu.github.io/ct-zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> David Egolf <a href="https://mattecapu.github.io/ct-zulip-archive/stream/274877-practice:-our-work/topic/topic_Morgan.20Rogers.html#294446625">(Aug 20 2022 at 14:12)</a>:</h4>
<p>In the little work I've done in this direction - testing experimentally to see if this approach can produce images with finer resolution - we've rigged things in our favour, by imaging toy systems that we know are sparse (simple) with respect to a chosen basis. It seems like we can make great images in that setting, which is kind of exciting. But once one wants to apply this work to real biological systems, then yes, I think it probably gets much harder.</p>
<p>Incidentally, I happened to run across this article  "Kolmogorov Complexity of Categories" (<a href="https://arxiv.org/pdf/1306.2675.pdf">https://arxiv.org/pdf/1306.2675.pdf</a>). It reminded me of your linked posts, and so I thought I might as well share a link here, in case it might be relevant.</p>



{% endraw %}

<hr><p>Last updated: Nov 01 2022 at 01:11 UTC</p>